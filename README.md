# ğŸ¤– Real-Time Hand Gesture Recognition using CVZone & TensorFlow

This project uses a webcam to recognize and classify hand gestures in real time. It combines `cvzone` for hand tracking and `TensorFlow/Keras` (trained using Teachable Machine) for gesture classification. Itâ€™s a cool application of computer vision and deep learning!

---

## ğŸ§° Technologies Used

| Tool | Purpose |
|------|---------|
| [cvzone](https://github.com/cvzone/cvzone) | Simplifies OpenCV tasks, used for hand tracking |
| [OpenCV (cv2)](https://opencv.org/) | Real-time video processing |
| [NumPy](https://numpy.org/) | Image matrix manipulation |
| [Teachable Machine](https://teachablemachine.withgoogle.com/) | Easy model training for hand gestures |
| [TensorFlow/Keras](https://www.tensorflow.org/) | Used to load and run the trained model |

---

## ğŸ“ Project Structure

  ```bash
  â”œâ”€â”€ Model/
  â”‚   â”œâ”€â”€ keras_model.h5         # Trained model from Teachable Machine
  â”‚   â””â”€â”€ labels.txt             # Corresponding labels
  â”œâ”€â”€ Data/
  â”‚   â””â”€â”€ 1/                     # Saved cropped hand images
  â”œâ”€â”€ dataCollection.py          # Script to collect hand image data
  â”œâ”€â”€ test.py                    # Script to test real-time classification
  â”œâ”€â”€ README.md                  # This file
  ```

---

## ğŸš€ How to Run the Project
  1. Clone the Repository
     ```bash
     git clone https://github.com/yourusername/hand-gesture-recognition.git
     cd hand-gesture-recognition
     ```

  2. Install Dependencies:
     Make sure you have Python 3.7+ and install the required libraries
     ```bash
     pip install cvzone opencv-python numpy tensorflow
     ```
  
  4. python dataCollection.py:
     Collect hand images by pressing s to save
     ```bash
     python dataCollection.py
     ```

  5. Run the Real-Time Classifier:
     This will open the webcam and start predicting
      ```bash
      python test.py
      ```
## ğŸ§  How It Works
Hand Detection: cvzone.HandTrackingModule detects the hand and returns bounding box coordinates.

Image Preprocessing: The hand region is cropped and resized to a 300x300 white canvas.

Prediction: The cropped image is passed to a pre-trained model using cvzone.ClassificationModule.

Display: The predicted gesture label and confidence score are shown on the webcam feed.

## âœ¨ Future Improvements
Add more gesture classes

Improve model accuracy by collecting more data

Add voice commands or system control integration

## ğŸ“¬ Contact
Created with ğŸ’™ by Hemanth Kumar

Feel free to connect on www.linkedin.com/in/hemanthkumar001
Or drop a â­ï¸ if you like the project!
